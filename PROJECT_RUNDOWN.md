# ðŸš€ AI Farm Water Management System - Complete Project Rundown

The **AI Farm Water Management System** is an intelligent water cooling system for AI farm data servers that uses machine learning to predict heat spikes before they occur, enabling proactive cooling instead of reactive flooding. The system consists of a Flask backend (deployed on Render) managing 24 server areas across 4 racks (6 servers per rack) with real-time simulation that generates heat spikes, calculates heat diffusion between neighboring servers, and applies cooling logic based on either Standard (reactive, activates cooling when temp >85Â°F) or AI (predictive, uses ML predictions with >70% spike probability) modes. The backend includes a dual ML model architecture (Gradient Boosting or Random Forest fallback) with a temperature regression model and spike classification model that uses 40+ engineered features including temporal patterns (hour, day, cyclical encoding), lag features (1-10 steps back), rolling statistics (mean, std, max, min across 3-24 window sizes), trend analysis (temperature changes and acceleration), spike history (counts and time since last spike), and spatial features (neighbor temperature statistics). The frontend (deployed on Netlify) features a sidebar with system mode toggles (Standard Reactive vs AI Predictive), auto-spike generation toggle, action buttons (Start/Stop simulation, Trigger Spike, Retrain Model), and global status display (simulation state, model confidence percentage, total spike count), plus a main content area with a Three.js 3D visualization showing the server room with color-coded server meshes (green <80Â°F, yellow 80-85Â°F, orange 85-90Â°F, red >90Â°F, blue when cooling active) and a responsive grid of 24 server cards displaying server ID (SRV-00 to SRV-23), current temperature (color-coded), predicted temperature, spike probability (color-coded: green â‰¤40%, yellow 40-70%, red >70%), and cooling status indicator. The system polls the backend API every 2 seconds for status updates, the simulation loop runs every 1 second updating temperatures and applying cooling, heat spikes can be auto-generated (15% chance per cycle) or manually triggered, and the ML model can be retrained on-demand with progress indicators showing training stages. The API provides endpoints for status monitoring (`/api/status` returns areas array, predictions object, simulation state, system mode), simulation control (start/stop, trigger spike, toggle auto-spikes), system configuration (set mode, activate/deactivate cooling per area), ML operations (retrain model, get predictions), and data management (record heat spikes, fetch online datasets, get history). The UI uses a dark theme with CSS variables for consistent theming, features smooth transitions and animations, and displays real-time updates through color changes, progress bars, and status badges.
